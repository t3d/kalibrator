# vim:fileencoding=UTF-8:ts=4:sw=4:sta:et:sts=4:ai
import re
from calibre.web.feeds.news import BasicNewsRecipe
class Computerworld_pl(BasicNewsRecipe):
    title          = u'Computerworld.pl'
    __author__        = 'fenuks'
    description   = u'Serwis o IT w przemyśle, finansach, handlu, administracji oraz rynku IT i telekomunikacyjnym - wiadomości, opinie, analizy, porady prawne'
    category       = 'IT'
    language       = 'pl'
    masthead_url = 'http://g1.computerworld.pl/cw/beta_gfx/cw2.gif'
    cover_url = 'http://g1.computerworld.pl/cw/beta_gfx/cw2.gif'
    no_stylesheets = True
    oldest_article = 7
    max_articles_per_feed = 100
    remove_attributes = ['style',]
    preprocess_regexps = [(re.compile(u'Zobacz również:', re.IGNORECASE), lambda m: ''), (re.compile(ur'[*]+reklama[*]+', re.IGNORECASE), lambda m: ''),]
    keep_only_tags = [dict(id=['szpaltaL', 's2011'])]
    remove_tags_after = dict(name='div', attrs={'class':'tresc'})
    remove_tags = [dict(attrs={'class':['nnav', 'rMobi', 'tagi', 'rec']}), dict(name='a', attrs={'target':'_blank'})]
    feeds          = [(u'Wiadomo\u015bci', u'http://rssout.idg.pl/cw/news_iso.xml')]

    def skip_ad_pages(self, soup):
        if soup.title.string.lower() == 'advertisement':
          tag = soup.find(name='a')
          if tag:
            new_soup = self.index_to_soup(tag['href'], raw=True)
            return new_soup